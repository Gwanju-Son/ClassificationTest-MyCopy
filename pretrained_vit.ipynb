{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning with Pre-trained ViT on CIFAR-10\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juho127/ClassificationTest/blob/main/pretrained_vit.ipynb)\n",
        "\n",
        "In this notebook, we'll use a **pre-trained Vision Transformer (ViT)** model from ImageNet and fine-tune it on CIFAR-10.\n",
        "\n",
        "## What is Transfer Learning?\n",
        "\n",
        "Transfer learning uses knowledge learned from one task (ImageNet classification) and applies it to another task (CIFAR-10 classification).\n",
        "\n",
        "### Benefits:\n",
        "- ‚úì Much better performance (can reach 90%+ accuracy!)\n",
        "- ‚úì Faster training (fewer epochs needed)\n",
        "- ‚úì Works well with small datasets\n",
        "- ‚úì Learns better features\n",
        "\n",
        "### Comparison:\n",
        "- **Training from scratch**: ~65-70% (from previous notebook)\n",
        "- **Transfer learning**: ~85-95% (this notebook)\n",
        "\n",
        "## Learning Goals:\n",
        "1. Load pre-trained models using `timm` library\n",
        "2. Understand fine-tuning strategies\n",
        "3. Compare different ViT model sizes\n",
        "4. Achieve state-of-the-art results on CIFAR-10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úì Running on Google Colab\")\n",
        "    print(\"üìå Tip: Runtime > Change runtime type > GPU for faster training!\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚úì Running on local environment\")\n",
        "\n",
        "# Install required packages on Colab\n",
        "if IN_COLAB:\n",
        "    print(\"\\nInstalling packages...\")\n",
        "    import sys\n",
        "    # timm: PyTorch Image Models (for pre-trained models)\n",
        "    !{sys.executable} -m pip install -q torch torchvision tqdm matplotlib timm\n",
        "    print(\"‚úì Packages installed!\")\n",
        "else:\n",
        "    print(\"\\nMake sure you have installed: torch torchvision tqdm matplotlib timm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import timm  # PyTorch Image Models\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"timm version: {timm.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"üéâ You can use GPU for faster training!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Hyperparameters and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-4  # Lower learning rate for fine-tuning\n",
        "NUM_EPOCHS = 10  # Fewer epochs needed with pre-trained model\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# CIFAR-10 classes\n",
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print(f\"Device: {DEVICE}\")\n",
        "if DEVICE.type == 'cuda':\n",
        "    print(\"‚úì Using GPU!\")\n",
        "else:\n",
        "    print(\"‚Ñπ Using CPU (Colab: Runtime > Change runtime type > GPU)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preprocessing with strong augmentation\n",
        "# Note: Pre-trained models expect 224x224 images\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),  # Resize CIFAR-10 from 32x32 to 224x224\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    # ImageNet normalization (important for pre-trained models!)\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "print(\"Loading dataset...\")\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "print(f\"\\n‚ö†Ô∏è Note: Images are resized from 32x32 to 224x224 for pre-trained models\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample images\n",
        "def show_images(loader, num_images=10):\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "    \n",
        "    # Denormalize for visualization\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    images = images * std + mean\n",
        "    images = torch.clamp(images, 0, 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    fig.suptitle('CIFAR-10 Sample Images (Resized to 224x224)', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        if idx < num_images:\n",
        "            img = images[idx].numpy().transpose((1, 2, 0))\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(f'{CLASSES[labels[idx]]}', fontsize=10)\n",
        "            ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_images(train_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Explore Available Pre-trained Models\n",
        "\n",
        "Let's check what ViT models are available in the `timm` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List available ViT models\n",
        "vit_models = timm.list_models('vit*', pretrained=True)\n",
        "print(f\"Available pre-trained ViT models: {len(vit_models)}\")\n",
        "print(\"\\nSome popular models:\")\n",
        "for model in vit_models[:10]:\n",
        "    print(f\"  - {model}\")\n",
        "    \n",
        "print(\"\\nüí° We'll use 'vit_tiny_patch16_224' (smallest, fastest for practice)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Pre-trained Model\n",
        "\n",
        "We'll load a pre-trained ViT model and modify it for CIFAR-10 (10 classes).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_pretrained_vit(model_name='vit_tiny_patch16_224', num_classes=10):\n",
        "    \"\"\"\n",
        "    Create a pre-trained ViT model and modify the classifier head\n",
        "    \n",
        "    Args:\n",
        "        model_name: Name of the pre-trained model\n",
        "        num_classes: Number of output classes (10 for CIFAR-10)\n",
        "    \"\"\"\n",
        "    print(f\"Loading pre-trained model: {model_name}\")\n",
        "    \n",
        "    # Load pre-trained model (trained on ImageNet with 1000 classes)\n",
        "    model = timm.create_model(model_name, pretrained=True)\n",
        "    \n",
        "    # Get the number of features in the classifier\n",
        "    num_features = model.head.in_features\n",
        "    \n",
        "    # Replace the classifier head for CIFAR-10 (10 classes)\n",
        "    model.head = nn.Linear(num_features, num_classes)\n",
        "    \n",
        "    print(f\"‚úì Model loaded successfully!\")\n",
        "    print(f\"  - Original task: ImageNet (1000 classes)\")\n",
        "    print(f\"  - New task: CIFAR-10 ({num_classes} classes)\")\n",
        "    print(f\"  - Classifier head replaced: {num_features} -> {num_classes}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_pretrained_vit().to(DEVICE)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel Parameters:\")\n",
        "print(f\"  Total: {total_params:,}\")\n",
        "print(f\"  Trainable: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fine-tuning Strategies\n",
        "\n",
        "There are different ways to fine-tune a pre-trained model:\n",
        "\n",
        "### Strategy 1: Fine-tune all layers\n",
        "- Train all parameters\n",
        "- More flexible but slower\n",
        "- Risk of overfitting on small datasets\n",
        "\n",
        "### Strategy 2: Feature extraction (freeze backbone)\n",
        "- Only train the new classifier head\n",
        "- Faster training\n",
        "- Good for very small datasets\n",
        "\n",
        "### Strategy 3: Gradual unfreezing\n",
        "- Start with frozen backbone, then gradually unfreeze layers\n",
        "- Best of both worlds\n",
        "\n",
        "**We'll use Strategy 1** for simplicity and good performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Freeze backbone for feature extraction only\n",
        "# Uncomment the lines below to try Strategy 2\n",
        "\n",
        "# for name, param in model.named_parameters():\n",
        "#     if 'head' not in name:  # Freeze all except classifier head\n",
        "#         param.requires_grad = False\n",
        "# \n",
        "# print(\"Backbone frozen! Only classifier head will be trained.\")\n",
        "# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "# print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "print(\"Using Strategy 1: Fine-tune all layers\")\n",
        "print(f\"All {trainable_params:,} parameters will be trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, epoch):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{running_loss/total:.4f}',\n",
        "            'acc': f'{100*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc='Evaluating'):\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    test_loss = test_loss / total\n",
        "    test_acc = 100 * correct / total\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "print(\"Training functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train the Model\n",
        "\n",
        "Now let's fine-tune the pre-trained ViT model on CIFAR-10!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
        "\n",
        "# Learning rate scheduler (optional but recommended)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
        "\n",
        "# Training loop\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "test_losses = []\n",
        "test_accs = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Train\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    # Evaluate\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accs.append(test_acc)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
        "    print(f\"  Test  - Loss: {test_loss:.4f}, Acc: {test_acc:.2f}%\")\n",
        "    print(f\"  LR: {current_lr:.6f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'pretrained_vit_best.pth')\n",
        "        print(f\"  ‚úì Best model saved (Accuracy: {best_acc:.2f}%)\")\n",
        "    \n",
        "    print(\"-\" * 60)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Training Complete!\")\n",
        "print(f\"Total training time: {training_time/60:.2f} minutes\")\n",
        "print(f\"Best test accuracy: {best_acc:.2f}%\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "epochs = range(1, NUM_EPOCHS + 1)\n",
        "\n",
        "# Loss graph\n",
        "ax1.plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=2, marker='o')\n",
        "ax1.plot(epochs, test_losses, 'r-', label='Test Loss', linewidth=2, marker='s')\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.set_title('Training History: Loss', fontsize=14, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy graph\n",
        "ax2.plot(epochs, train_accs, 'b-', label='Train Accuracy', linewidth=2, marker='o')\n",
        "ax2.plot(epochs, test_accs, 'r-', label='Test Accuracy', linewidth=2, marker='s')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax2.set_title('Training History: Accuracy', fontsize=14, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('pretrained_vit_training.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Training history saved as 'pretrained_vit_training.png'\")\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"  Best Test Accuracy: {best_acc:.2f}%\")\n",
        "print(f\"  Final Train Accuracy: {train_accs[-1]:.2f}%\")\n",
        "print(f\"  Final Test Accuracy: {test_accs[-1]:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Per-Class Accuracy Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate per-class accuracy\n",
        "class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# Calculate and plot\n",
        "class_acc = [100 * class_correct[i] / class_total[i] for i in range(10)]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bars = ax.bar(CLASSES, class_acc, color='steelblue', alpha=0.8)\n",
        "ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Per-Class Accuracy (Pre-trained ViT)', fontsize=14, fontweight='bold')\n",
        "ax.set_ylim([0, 100])\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, class_acc):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{acc:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('pretrained_vit_per_class.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPer-Class Accuracy:\")\n",
        "print(\"=\" * 40)\n",
        "for i, cls in enumerate(CLASSES):\n",
        "    print(f\"  {cls:10s}: {class_acc[i]:.2f}%\")\n",
        "print(\"=\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualize Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "def visualize_predictions(model, loader, num_images=10):\n",
        "    model.eval()\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "    \n",
        "    # Denormalize for visualization\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    images_display = images * std + mean\n",
        "    images_display = torch.clamp(images_display, 0, 1)\n",
        "    \n",
        "    images = images.to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        confidences, predicted = torch.max(probabilities, 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
        "    fig.suptitle('Pre-trained ViT Predictions', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        if idx < num_images:\n",
        "            img = images_display[idx].numpy().transpose((1, 2, 0))\n",
        "            ax.imshow(img)\n",
        "            \n",
        "            pred_label = CLASSES[predicted[idx]]\n",
        "            true_label = CLASSES[labels[idx]]\n",
        "            conf = confidences[idx].item()\n",
        "            \n",
        "            color = 'green' if predicted[idx] == labels[idx] else 'red'\n",
        "            ax.set_title(f'Pred: {pred_label} ({conf:.2%})\\nTrue: {true_label}', \n",
        "                        color=color, fontsize=9, fontweight='bold')\n",
        "            ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Compare with Training from Scratch\n",
        "\n",
        "Let's compare the performance of pre-trained vs. from-scratch models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison table\n",
        "comparison_data = {\n",
        "    'Method': ['Training from Scratch', 'Transfer Learning (Pre-trained)'],\n",
        "    'Accuracy': ['~65-70%', f'{best_acc:.2f}%'],\n",
        "    'Training Time': ['~20-30 min (20 epochs)', f'{training_time/60:.1f} min ({NUM_EPOCHS} epochs)'],\n",
        "    'Convergence': ['Slower', 'Faster'],\n",
        "    'Data Efficiency': ['Needs more data', 'Works with less data']\n",
        "}\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPARISON: Training from Scratch vs. Transfer Learning\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Method':<35} {'Accuracy':<15} {'Training Time':<20}\")\n",
        "print(\"-\" * 80)\n",
        "for i in range(len(comparison_data['Method'])):\n",
        "    print(f\"{comparison_data['Method'][i]:<35} \"\n",
        "          f\"{comparison_data['Accuracy'][i]:<15} \"\n",
        "          f\"{comparison_data['Training Time'][i]:<20}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nüéØ Key Takeaways:\")\n",
        "print(\"  1. Pre-trained models achieve MUCH better accuracy (+20-25%)\")\n",
        "print(\"  2. Faster convergence (fewer epochs needed)\")\n",
        "print(\"  3. More stable training (less overfitting)\")\n",
        "print(\"  4. Better feature extraction from ImageNet knowledge\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Try Different Model Sizes (Optional)\n",
        "\n",
        "The `timm` library provides various ViT model sizes. Let's compare them!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different ViT model sizes\n",
        "model_variants = [\n",
        "    'vit_tiny_patch16_224',   # Smallest, fastest\n",
        "    'vit_small_patch16_224',  # Medium size\n",
        "    'vit_base_patch16_224',   # Larger, better accuracy but slower\n",
        "]\n",
        "\n",
        "print(\"Available ViT Model Variants:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Model Name':<30} {'Parameters':<20} {'Speed':<20}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for variant in model_variants:\n",
        "    try:\n",
        "        temp_model = timm.create_model(variant, pretrained=False)\n",
        "        params = sum(p.numel() for p in temp_model.parameters()) / 1e6\n",
        "        \n",
        "        if 'tiny' in variant:\n",
        "            speed = \"‚ö° Fast\"\n",
        "        elif 'small' in variant:\n",
        "            speed = \"‚Üí Medium\"\n",
        "        else:\n",
        "            speed = \"üêå Slower\"\n",
        "        \n",
        "        print(f\"{variant:<30} {params:.1f}M parameters    {speed:<20}\")\n",
        "        del temp_model\n",
        "    except:\n",
        "        print(f\"{variant:<30} Not available\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nüí° Recommendation:\")\n",
        "print(\"  - For practice: vit_tiny_patch16_224 (fast, good accuracy)\")\n",
        "print(\"  - For best results: vit_base_patch16_224 (slower, better accuracy)\")\n",
        "print(\"\\nTo try a different model, change the model_name in Section 4!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Key Concepts Summary\n",
        "\n",
        "### What is Transfer Learning?\n",
        "Transfer learning uses knowledge from a **source task** (ImageNet) to improve performance on a **target task** (CIFAR-10).\n",
        "\n",
        "### Why does it work?\n",
        "1. **Low-level features are universal**: Edge detectors, color filters work across datasets\n",
        "2. **High-level features transfer**: Object parts, shapes are similar\n",
        "3. **Pre-trained weights are better initialization**: Better than random initialization\n",
        "\n",
        "### When to use Transfer Learning?\n",
        "‚úÖ **Use when:**\n",
        "- Limited training data\n",
        "- Similar domain (images ‚Üí images)\n",
        "- Want faster training\n",
        "- Want better performance\n",
        "\n",
        "‚ùå **Don't use when:**\n",
        "- Very different domains (images ‚Üí text)\n",
        "- Huge amount of target data\n",
        "- Very specific task that's very different from source\n",
        "\n",
        "### Fine-tuning Strategies:\n",
        "1. **Feature Extraction**: Freeze backbone, train only classifier\n",
        "2. **Fine-tune all**: Train all layers (we used this)\n",
        "3. **Gradual unfreezing**: Start frozen, gradually unfreeze layers\n",
        "4. **Discriminative learning rates**: Different learning rates for different layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Exercises\n",
        "\n",
        "Try these experiments to deepen your understanding:\n",
        "\n",
        "### Easy:\n",
        "1. **Change learning rate**: Try `1e-3`, `1e-5` and compare results\n",
        "2. **Change number of epochs**: Try 5, 15, 20 epochs\n",
        "3. **Try different model**: Use `vit_small_patch16_224` instead\n",
        "\n",
        "### Medium:\n",
        "4. **Feature extraction**: Uncomment the freeze code in Section 5\n",
        "   - Compare training time and accuracy\n",
        "5. **Data augmentation**: Remove some augmentations from transform_train\n",
        "   - See how it affects overfitting\n",
        "\n",
        "### Hard:\n",
        "6. **Implement gradual unfreezing**:\n",
        "   - Freeze all layers initially\n",
        "   - Unfreeze one block at a time every few epochs\n",
        "7. **Try other architectures**:\n",
        "   - ResNet: `resnet50`, `resnet101`\n",
        "   - EfficientNet: `efficientnet_b0`, `efficientnet_b3`\n",
        "8. **Ensemble methods**: Train multiple models and combine predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Save Model (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the final model\n",
        "torch.save(model.state_dict(), 'pretrained_vit_final.pth')\n",
        "print(\"‚úì Model saved as 'pretrained_vit_final.pth'\")\n",
        "\n",
        "# To load the model later:\n",
        "# model = create_pretrained_vit()\n",
        "# model.load_state_dict(torch.load('pretrained_vit_final.pth'))\n",
        "# model.to(DEVICE)\n",
        "# model.eval()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CONGRATULATIONS! üéâ\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"You successfully fine-tuned a pre-trained ViT model!\")\n",
        "print(f\"Final test accuracy: {best_acc:.2f}%\")\n",
        "print(f\"\\nThis is much better than training from scratch (~65-70%)!\")\n",
        "print(\"=\" * 70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
