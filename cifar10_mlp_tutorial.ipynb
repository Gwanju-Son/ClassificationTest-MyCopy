{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CIFAR-10 MLP ë¶„ë¥˜ ì‹¤ìŠµ\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juho127/ClassificationTest/blob/main/cifar10_mlp_tutorial.ipynb)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” CIFAR-10 ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (MLP)ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸš€ Google Colabì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°\n",
        "1. **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPU** ì„ íƒ (í•™ìŠµ ì†ë„ê°€ í›¨ì”¬ ë¹¨ë¼ì§‘ë‹ˆë‹¤!)\n",
        "2. ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ (Shift + Enter)\n",
        "\n",
        "## ëª©ì°¨\n",
        "1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "2. ë°ì´í„°ì…‹ ë¡œë“œ ë° íƒìƒ‰\n",
        "3. MLP ëª¨ë¸ ì •ì˜\n",
        "4. í•™ìŠµ ë° í‰ê°€\n",
        "5. ê²°ê³¼ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. í™˜ê²½ ì„¤ì • (Google Colab ì „ìš©)\n",
        "\n",
        "**Colabì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°**: ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.  \n",
        "**ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°**: ì•„ë˜ ì…€ì„ ê±´ë„ˆë›°ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Colab í™˜ê²½ í™•ì¸ ë° ì„¤ì •\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"âœ“ Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.\")\n",
        "    print(\"ğŸ“Œ íŒ: ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPUë¥¼ ì„ íƒí•˜ë©´ ë” ë¹ ë¦…ë‹ˆë‹¤!\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"âœ“ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.\")\n",
        "\n",
        "# Colabì—ì„œ í•„ìš”í•œ ê²½ìš° ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "if IN_COLAB:\n",
        "    print(\"\\ní•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ í™•ì¸í•˜ëŠ” ì¤‘...\")\n",
        "    # Colabì—ëŠ” ëŒ€ë¶€ë¶„ ì„¤ì¹˜ë˜ì–´ ìˆì§€ë§Œ, í™•ì¸ì°¨ ì‹¤í–‰\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install -q torch torchvision tqdm matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
        "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"ğŸ‰ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê²Œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ë°ì´í„°ì…‹ ë¡œë“œ ë° íƒìƒ‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10  # ë…¸íŠ¸ë¶ì—ì„œëŠ” ì§§ê²Œ ì„¤ì • (ì‹œê°„ì´ ìˆë‹¤ë©´ 20ìœ¼ë¡œ ëŠ˜ë ¤ë³´ì„¸ìš”!)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# CIFAR-10 í´ë˜ìŠ¤ ì´ë¦„\n",
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {DEVICE}\")\n",
        "if DEVICE.type == 'cuda':\n",
        "    print(\"âœ“ GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤!\")\n",
        "else:\n",
        "    print(\"â„¹ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (Colabì˜ ê²½ìš°: ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPU)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ì „ì²˜ë¦¬\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}ê°œ\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)}ê°œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”\n",
        "def show_images(loader, num_images=10):\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "    \n",
        "    # ì •ê·œí™” í•´ì œ\n",
        "    images = images / 2 + 0.5\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    fig.suptitle('CIFAR-10 ìƒ˜í”Œ ì´ë¯¸ì§€', fontsize=16)\n",
        "    \n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        if idx < num_images:\n",
        "            img = images[idx].numpy().transpose((1, 2, 0))\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(f'{CLASSES[labels[idx]]}')\n",
        "            ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_images(train_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MLP ëª¨ë¸ ì •ì˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ëª¨ë¸\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size=3072, hidden_size1=512, hidden_size2=256, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        \n",
        "        # ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        \n",
        "        # ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        \n",
        "        # ì¶œë ¥ì¸µ\n",
        "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # ì´ë¯¸ì§€ë¥¼ 1ì°¨ì›ìœ¼ë¡œ í¼ì¹˜ê¸° (32x32x3 = 3072)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        # ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        \n",
        "        # ì¶œë ¥ì¸µ\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "model = MLP().to(DEVICE)\n",
        "print(model)\n",
        "\n",
        "# íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. í•™ìŠµ ë° í‰ê°€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•™ìŠµ í•¨ìˆ˜\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        \n",
        "        # ìˆœì „íŒŒ\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # ì—­ì „íŒŒ ë° ìµœì í™”\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # í†µê³„\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{running_loss/total:.4f}',\n",
        "            'acc': f'{100*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# í‰ê°€ í•¨ìˆ˜\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    test_loss = test_loss / total\n",
        "    test_acc = 100 * correct / total\n",
        "    return test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•™ìŠµ ì‹œì‘\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "test_losses = []\n",
        "test_accs = []\n",
        "\n",
        "print(\"í•™ìŠµ ì‹œì‘!\\n\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # í•™ìŠµ\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    # í‰ê°€\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accs.append(test_acc)\n",
        "    \n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(f\"  í›ˆë ¨ - ì†ì‹¤: {train_loss:.4f}, ì •í™•ë„: {train_acc:.2f}%\")\n",
        "    print(f\"  í…ŒìŠ¤íŠ¸ - ì†ì‹¤: {test_loss:.4f}, ì •í™•ë„: {test_acc:.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(\"\\ní•™ìŠµ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ê²°ê³¼ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•™ìŠµ ê³¼ì • ì‹œê°í™”\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "# ì†ì‹¤ ê·¸ë˜í”„\n",
        "ax1.plot(epochs, train_losses, 'b-', label='í›ˆë ¨ ì†ì‹¤', linewidth=2)\n",
        "ax1.plot(epochs, test_losses, 'r-', label='í…ŒìŠ¤íŠ¸ ì†ì‹¤', linewidth=2)\n",
        "ax1.set_xlabel('ì—í¬í¬', fontsize=12)\n",
        "ax1.set_ylabel('ì†ì‹¤', fontsize=12)\n",
        "ax1.set_title('í•™ìŠµ ê³¼ì •: ì†ì‹¤', fontsize=14)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# ì •í™•ë„ ê·¸ë˜í”„\n",
        "ax2.plot(epochs, train_accs, 'b-', label='í›ˆë ¨ ì •í™•ë„', linewidth=2)\n",
        "ax2.plot(epochs, test_accs, 'r-', label='í…ŒìŠ¤íŠ¸ ì •í™•ë„', linewidth=2)\n",
        "ax2.set_xlabel('ì—í¬í¬', fontsize=12)\n",
        "ax2.set_ylabel('ì •í™•ë„ (%)', fontsize=12)\n",
        "ax2.set_title('í•™ìŠµ ê³¼ì •: ì •í™•ë„', fontsize=14)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accs[-1]:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í´ë˜ìŠ¤ë³„ ì •í™•ë„ ê³„ì‚°\n",
        "class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "print(\"í´ë˜ìŠ¤ë³„ ì •í™•ë„:\")\n",
        "for i in range(10):\n",
        "    acc = 100 * class_correct[i] / class_total[i]\n",
        "    print(f'  {CLASSES[i]:10s}: {acc:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
        "def visualize_predictions(model, loader, num_images=10):\n",
        "    model.eval()\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "    images_display = images / 2 + 0.5  # ì •ê·œí™” í•´ì œ\n",
        "    \n",
        "    images = images.to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    fig.suptitle('ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼', fontsize=16)\n",
        "    \n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        if idx < num_images:\n",
        "            img = images_display[idx].numpy().transpose((1, 2, 0))\n",
        "            ax.imshow(img)\n",
        "            \n",
        "            pred_label = CLASSES[predicted[idx]]\n",
        "            true_label = CLASSES[labels[idx]]\n",
        "            color = 'green' if predicted[idx] == labels[idx] else 'red'\n",
        "            \n",
        "            ax.set_title(f'ì˜ˆì¸¡: {pred_label}\\nì •ë‹µ: {true_label}', color=color)\n",
        "            ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ì‹¤ìŠµ ê³¼ì œ\n",
        "\n",
        "ë‹¤ìŒ ë‚´ìš©ì„ ì‹¤í—˜í•´ë³´ì„¸ìš”:\n",
        "\n",
        "1. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •**\n",
        "   - í•™ìŠµë¥ ì„ ë³€ê²½í•´ë³´ì„¸ìš” (0.0001, 0.01 ë“±)\n",
        "   - ë°°ì¹˜ í¬ê¸°ë¥¼ ë³€ê²½í•´ë³´ì„¸ìš” (64, 256 ë“±)\n",
        "   - ì—í¬í¬ ìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”\n",
        "\n",
        "2. **ëª¨ë¸ êµ¬ì¡° ë³€ê²½**\n",
        "   - ì€ë‹‰ì¸µì„ ì¶”ê°€í•´ë³´ì„¸ìš”\n",
        "   - ì€ë‹‰ì¸µì˜ ë‰´ëŸ° ìˆ˜ë¥¼ ë³€ê²½í•´ë³´ì„¸ìš”\n",
        "   - Dropout ë¹„ìœ¨ì„ ë³€ê²½í•´ë³´ì„¸ìš”\n",
        "\n",
        "3. **ê²°ê³¼ ë¶„ì„**\n",
        "   - ì–´ë–¤ í´ë˜ìŠ¤ê°€ ë¶„ë¥˜í•˜ê¸° ì–´ë ¤ìš´ê°€ìš”?\n",
        "   - ê³¼ì í•©(Overfitting)ì´ ë°œìƒí•˜ë‚˜ìš”?\n",
        "   - MLPì˜ í•œê³„ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
